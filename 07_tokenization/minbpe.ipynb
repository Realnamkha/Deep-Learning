{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d4719065-ff79-4e09-a287-fbb81216d0e7",
   "metadata": {},
   "source": [
    "Step 1\n",
    "Write the BasicTokenizer class, with the following three core functions:\n",
    "\n",
    "def train(self, text, vocab_size, verbose=False)\n",
    "def encode(self, text)\n",
    "def decode(self, ids)\n",
    "Train your tokenizer on whatever text you like and visualize the merged tokens. Do they look reasonable? One default test you may wish to use is the text file tests/taylorswift.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55997653-4b8b-4e17-9f79-677c2212a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('m', 'e'): 1, ('e', 's'): 1, ('s', 's'): 2, ('s', 'i'): 1, ('i', 's'): 1}\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids,ids[1:]):\n",
    "        counts[pair] = counts.get(pair,0) + 1\n",
    "    return counts\n",
    "        \n",
    "text = \"messiss\"\n",
    "print(get_stats(text))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac2993-fda1-422e-8f2d-fddaf7b0cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids,pair,idx):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats,key=stats.get())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
